# Лабораторні роботи 7-8: Лінійна та поліноміальна регресія

Цей репозиторій містить виконання лабораторних робіт з машинного навчання на тему регресійного аналізу.

## Структура проекту

```
lab7-8/
├── !materials/               # Вхідні дані
│   ├── data_singlevar_regr.txt
│   ├── data_multivar_regr.txt
│   └── data_regr_1.txt ... data_regr_5.txt
├── LR_7_task_1.py           # Завдання 7.1: Регресор однієї змінної
├── LR_7_task_2.py           # Завдання 7.2: Передбачення регресією (Варіант 1)
├── LR_7_task_3.py           # Завдання 7.3: Багатовимірний регресор
├── LR_8_task_4.py           # Завдання 8.1: Регресія з датасетом діабету
├── LR_8_task_2.py           # Завдання 8.2 та 8.3: Самостійна регресія + криві навчання
├── requirements.txt         # Залежності
└── README.md               # Цей файл
```

## Встановлення залежностей

```bash
pip install -r requirements.txt
```

## Опис завдань

### Лабораторна робота 7

#### Завдання 7.1 (LR_7_task_1.py)
Створення регресора однієї змінної з використанням файлу `data_singlevar_regr.txt`.
- Розбиття даних на навчальний та тестовий набори
- Навчання лінійної регресійної моделі
- Візуалізація результатів
- Обчислення метрик якості (MAE, MSE, R²)
- Збереження та завантаження моделі

#### Завдання 7.2 (LR_7_task_2.py)
Передбачення за допомогою регресії однієї змінної (Варіант 1 - файл `data_regr_1.txt`).
Аналогічно до завдання 7.1, але з іншими даними.

#### Завдання 7.3 (LR_7_task_3.py)
Створення багатовимірного регресора з використанням файлу `data_multivar_regr.txt`.
- Лінійна регресія для багатьох змінних
- Поліноміальна регресія 10-го ступеня
- Порівняння результатів лінійної та поліноміальної регресії
- Прогноз для тестової точки

### Лабораторна робота 8

#### Завдання 8.1 (LR_8_task_4.py)
Регресія багатьох змінних з використанням датасету діабету зі sklearn.
- Робота з 442 зразками та 10 ознаками
- Навчання моделі лінійної регресії
- Візуалізація передбачень та залишків
- Аналіз важливості ознак
- Обчислення R², MAE, MSE

#### Завдання 8.2 та 8.3 (LR_8_task_2.py)
Самостійна побудова регресії та аналіз кривих навчання (Варіант 1).
- Генерація даних за формулою: `y = 0.5*X² + X + 2 + шум`
- Лінійна регресія
- Поліноміальна регресія (степінь 2)
- Побудова кривих навчання для різних моделей (лінійна, поліном 2-го, 10-го ступеня)
- Аналіз недонавчання та перенавчання
- Порівняння моделей різних ступенів

## Запуск програм

Кожен файл можна запустити окремо:

```bash
# Лабораторна 7
python LR_7_task_1.py
python LR_7_task_2.py
python LR_7_task_3.py

# Лабораторна 8
python LR_8_task_4.py
python LR_8_task_2.py
```

## Результати

Програми генерують:
- Графіки у вигляді PNG файлів
- Збережені моделі у форматі .pkl (для завдань 7.1, 7.2)
- Метрики якості в консолі

## Метрики якості

Для оцінки якості моделей використовуються:
- **MAE** (Mean Absolute Error) - середня абсолютна помилка
- **MSE** (Mean Squared Error) - середньоквадратична помилка
- **R²** (Coefficient of Determination) - коефіцієнт детермінації
- **Median Absolute Error** - медіанна абсолютна помилка
- **Explained Variance Score** - пояснена дисперсія

## Варіанти

Код написано для **Варіанту 1**:
- Завдання 7.2: файл `data_regr_1.txt`
- Завдання 8.2: `y = 0.5*X² + X + 2 + шум`, `X = 6*rand(100,1) - 5`

Для іншого варіанту змініть відповідні рядки у файлах.

## Висновки

1. **Лінійна регресія** підходить для лінійних залежностей
2. **Поліноміальна регресія** краща для нелінійних даних
3. **Криві навчання** допомагають діагностувати недонавчання/перенавчання
4. **Підбір ступеня полінома** важливий для уникнення перенавчання
5. **Регуляризація** може покращити узагальнення моделі

## Автор

Виконано відповідно до методичних рекомендацій лабораторних робіт №7-8.

